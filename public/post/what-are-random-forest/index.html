<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="Rishabh Kumar">
<meta name="description" content="no  Random forest algorithm helps us to classify items into various groupings.There are two kinds of random forest algorithms: one for regressiona and one for clasifications. Both have similar underlying philosophies.
Before getting into random forest its important to know the workings of the Decision tree algorithm. It works in a way to find features that will split the data in resulting groups that are as different from each other and the memebers of th these groups are as similar to each other as possible." />
<meta name="keywords" content=", data science, How to do random forest, What are random forest" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="/post/what-are-random-forest/" />


    <title>
        
            What are Random Forest? :: Rishabh Kumar  â€” Decision and Data Scientist
        
    </title>



<link href="https://cdnjs.cloudflare.com/ajax/libs/flag-icon-css/3.2.1/css/flag-icon.min.css" rel="stylesheet"
    type="text/css">



<link rel="stylesheet" href="/main.min.753fac8f03736f0edc9be411eb20cee875dd7bb8e73c8155fbf6a629c863f4ca.css">






<meta itemprop="name" content="What are Random Forest?">
<meta itemprop="description" content="no  Random forest algorithm helps us to classify items into various groupings.There are two kinds of random forest algorithms: one for regressiona and one for clasifications. Both have similar underlying philosophies.
Before getting into random forest its important to know the workings of the Decision tree algorithm. It works in a way to find features that will split the data in resulting groups that are as different from each other and the memebers of th these groups are as similar to each other as possible.">
<meta itemprop="datePublished" content="2020-07-13T00:00:00&#43;00:00" />
<meta itemprop="dateModified" content="2020-07-13T00:00:00&#43;00:00" />
<meta itemprop="wordCount" content="706">
<meta itemprop="image" content="/"/>



<meta itemprop="keywords" content="data science,How to do random forest,What are random forest," />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="/"/>

<meta name="twitter:title" content="What are Random Forest?"/>
<meta name="twitter:description" content="no  Random forest algorithm helps us to classify items into various groupings.There are two kinds of random forest algorithms: one for regressiona and one for clasifications. Both have similar underlying philosophies.
Before getting into random forest its important to know the workings of the Decision tree algorithm. It works in a way to find features that will split the data in resulting groups that are as different from each other and the memebers of th these groups are as similar to each other as possible."/>





    <meta property="article:section" content="R" />

    <meta property="article:section" content="Machine Learning" />

    <meta property="article:section" content="Data Science" />

    <meta property="article:section" content="AI" />



    <meta property="article:published_time" content="2020-07-13 00:00:00 &#43;0000 UTC" />








    </head>

    <body class="dark-theme">
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">></span>
            <span class="logo__text">Home</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="/about">About me</a></li><li><a href="/post">Blog</a></li><li><a href="/post">Projects</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            

            <span class="theme-toggle unselectable"><svg class="theme-toggler" width="24" height="24" viewBox="0 0 48 48" fill="none" xmlns="http://www.w3.org/2000/svg">
  <path d="M22 41C32.4934 41 41 32.4934 41 22C41 11.5066 32.4934 3 22
  3C11.5066 3 3 11.5066 3 22C3 32.4934 11.5066 41 22 41ZM7 22C7
  13.7157 13.7157 7 22 7V37C13.7157 37 7 30.2843 7 22Z"/>
</svg>
</span>
        </span>
    </span>
</header>


            <div class="content">
                
    <main class="post">

        <div class="post-info">
            
            </p>
        </div>

        <article>
            <h2 class="post-title"><a href="/post/what-are-random-forest/">What are Random Forest?</a></h2>

            

            <div class="post-content">
                

<div id="TOC">
no
</div>

<p>Random forest algorithm helps us to classify items into various groupings.There are two kinds of random forest algorithms: one for regressiona and one for clasifications. Both have similar underlying philosophies.</p>
<p>Before getting into random forest its important to know the workings of the Decision tree algorithm. It works in a way to find features that will split the data in resulting groups that are as different from each other and the memebers of th these groups are as similar to each other as possible.</p>
<div id="classification" class="section level1">
<h1>Classification</h1>
<p>See the plot below to differentiate the blue circles and red triangles, the DT algorithm will split at point 3 and point 4 drawing a straight line to make the clusters as different to each other as possible. Simply it takes into account the majority view and then classifies the data based on that.</p>
</div>
<div id="regression" class="section level1">
<h1>Regression</h1>
<p>When it comes to regresstion the style of data changes as dependency comes into place. So the algorithm divides the data into various parts and then in a way classifies it. This also implies that the regression is peicewise cosntant [INSErt LInk]</p>
</div>
<div id="random-forest-example" class="section level1">
<h1>Random Forest example</h1>
<p>Random forest then relies on the wisdom of the crowds. So Basically the data is split into many parts like what is done in bootstrapping and then analysed.</p>
<p>Example</p>
<pre class="r"><code>library(tidyverse)
library(stringi)
library(styler)

library(caret)
library(klaR)

coffee_ratings &lt;- readr::read_csv(&quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-07-07/coffee_ratings.csv&quot;)


# Remove outlier
mdata &lt;- coffee_ratings %&gt;% dplyr::select(-country_of_origin, -variety) %&gt;%  filter( total_cup_points &gt;25)


m1 &lt;- lm(total_cup_points ~
     species + 
     aroma +
     flavor +
     acidity + 
     color +
     sweetness + 
     altitude_mean_meters +
     processing_method, 
     data = mdata) 


model_Data &lt;- m1$model
# Trying K fold cross validation
set.seed(101) # Set Seed so that same sample can be reproduced in future also
model_Data$total_cup_points &lt;- ifelse(model_Data$total_cup_points &gt;82.09, &quot;Good&quot;,
                                      &quot;Bad&quot;)
# Now Selecting 50% of data as sample from total &#39;n&#39; rows of the data
sample &lt;- sample.int(n = nrow(model_Data), size = floor(.50*nrow(model_Data)), replace = F)
train &lt;- model_Data[sample, ]
test  &lt;- model_Data[-sample, ]



# Define train control for k fold cross validation
train_control &lt;- trainControl(method=&quot;LGOCV&quot;, number=10)
# Fit Naive Bayes Model
model &lt;- train(total_cup_points~.,
               data=train,
               trControl=train_control,
               method=&quot;rf&quot;,
               importance=T)

# Summarise Results
print(model)</code></pre>
<pre><code>## Random Forest 
## 
## 467 samples
##   8 predictor
##   2 classes: &#39;Bad&#39;, &#39;Good&#39; 
## 
## No pre-processing
## Resampling: Repeated Train/Test Splits Estimated (10 reps, 75%) 
## Summary of sample sizes: 351, 351, 351, 351, 351, 351, ... 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##    2    0.8663793  0.7164522
##    7    0.8646552  0.7168245
##   13    0.8620690  0.7121044
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 2.</code></pre>
<pre class="r"><code>summary(model)</code></pre>
<pre><code>##                 Length Class      Mode     
## call               5   -none-     call     
## type               1   -none-     character
## predicted        467   factor     numeric  
## err.rate        1500   -none-     numeric  
## confusion          6   -none-     numeric  
## votes            934   matrix     numeric  
## oob.times        467   -none-     numeric  
## classes            2   -none-     character
## importance        52   -none-     numeric  
## importanceSD      39   -none-     numeric  
## localImportance    0   -none-     NULL     
## proximity          0   -none-     NULL     
## ntree              1   -none-     numeric  
## mtry               1   -none-     numeric  
## forest            14   -none-     list     
## y                467   factor     numeric  
## test               0   -none-     NULL     
## inbag              0   -none-     NULL     
## xNames            13   -none-     character
## problemType        1   -none-     character
## tuneValue          1   data.frame list     
## obsLevels          2   -none-     character
## param              1   -none-     list</code></pre>
<pre class="r"><code>model$results</code></pre>
<pre><code>##   mtry  Accuracy     Kappa AccuracySD    KappaSD
## 1    2 0.8663793 0.7164522 0.02412767 0.05055639
## 2    7 0.8646552 0.7168245 0.02539489 0.05214482
## 3   13 0.8620690 0.7121044 0.02537862 0.05390591</code></pre>
<pre class="r"><code>model$finalModel</code></pre>
<pre><code>## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry, importance = ..1) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 13.92%
## Confusion matrix:
##      Bad Good class.error
## Bad  147   39  0.20967742
## Good  26  255  0.09252669</code></pre>
<pre class="r"><code>gbmImp &lt;- varImp(model)
gbmImp</code></pre>
<pre><code>## rf variable importance
## 
##                                            Importance
## flavor                                        100.000
## acidity                                        85.754
## aroma                                          66.694
## sweetness                                      30.981
## altitude_mean_meters                           18.404
## colorBluish-Green                              14.379
## processing_methodOther                          9.987
## colorGreen                                      9.783
## processing_methodSemi-washed / Semi-pulped      7.041
## processing_methodPulped natural / honey         6.773
## colorNone                                       5.189
## speciesRobusta                                  3.408
## processing_methodWashed / Wet                   0.000</code></pre>
</div>

            </div>
        </article>

        <hr />

        <div class="post-info">
  				<p>
  					<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg><span class="tag"><a href="/tags/data-science">data science</a></span><span class="tag"><a href="/tags/how-to-do-random-forest">How to do random forest</a></span><span class="tag"><a href="/tags/what-are-random-forest">What are random forest</a></span>
  				</p>
			
			<script src="https://utteranc.es/client.js"
        repo="rishkum/websiteHello"
        issue-term="title"
        label="comments ðŸ’¬"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
  		</div>
    </main>

            </div>

            
                <footer class="footer">
    <div class="footer__inner">
        <div class="footer__content">
            <span>&copy; 2020</span>
            
            <span><a href="https://creativecommons.org/licenses/by-nc/4.0/" target="_blank" rel="noopener">Copyright Rishabh Kumar </a></span>
            <span> <a href="/posts/index.xml" target="_blank" title="rss"><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 20 20" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg></a></span>
        </div>
    </div>
    <div class="footer__inner">
        <div class="footer__content">
            <span>Powered by <a href="http://gohugo.io"> Hugo</a> <a>  and theme by </a>
            <a href="https://github.com/rhazdon">Djordje Atlialp</a></span> <br>
            
            <span>Made with <span style="color:red;"> &#10084; </span> by <a href="https://github.com/rishkum">Rishabh Kumar</a></span>
        </div>
    </div>
</footer>

            
        </div>

        




<script type="text/javascript" src="/bundle.min.4a69500057d68129e88f497d354afe68422eb56de6d15e45dbe2190858ea5a76bfcb096406f992984b241db45f47388ac57ab0376e3b32125bef7a8a6d0f06c4.js" integrity="sha512-SmlQAFfWgSnoj0l9NUr&#43;aEIutW3m0V5F2&#43;IZCFjqWna/ywlkBvmSmEskHbRfRziKxXqwN247MhJb73qKbQ8GxA=="></script>



    </body>
</html>
